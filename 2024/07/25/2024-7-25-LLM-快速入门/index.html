<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="SleepingFace Blog"><meta property="og:type" content="article"><meta property="og:image" content="https://wangzhendong20.github.io//img/home1.jpg"><meta property="twitter:image" content="https://wangzhendong20.github.io//img/home1.jpg"><meta name=title content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta property="og:title" content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta property="twitter:title" content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta name=description content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta property="og:description" content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta property="twitter:description" content="åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨"><meta property="twitter:card" content="summary"><meta name=keyword content="WangZhendong"><link rel="shortcut icon" href=/img/favicon.ico><title>åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨ | ç‹æŒ¯ä¸œçš„åšå®¢ | SleepingFace Blog</title>
<link rel=canonical href=/2024/07/25/2024-7-25-LLM-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>SleepingFace Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/java/>java</a></li><li><a href=/categories/leetcode/>leetcode</a></li><li><a href=/categories/llm/>llm</a></li><li><a href=/categories/other/>other</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/notes//>NOTES</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/home1.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/llm title=LLM>LLM</a></div><h1>åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨</h1><h2 class=subheading></h2><span class=meta>Posted by
SleepingFace
on
Thursday, July 25, 2024</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=åˆ©ç”¨llama-factoryå¾®è°ƒqwen2-å¿«é€Ÿå…¥é—¨>åˆ©ç”¨LLaMA-Factoryå¾®è°ƒQwen2-å¿«é€Ÿå…¥é—¨</h1><h2 id=0-qwen2ç³»åˆ—æ¨¡å‹åŸºç¡€ä¿¡æ¯>0. Qwen2ç³»åˆ—æ¨¡å‹åŸºç¡€ä¿¡æ¯</h2><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e6%a8%a1%e5%9e%8b%e5%9f%ba%e6%9c%ac%e4%bf%a1%e6%81%af.png alt=æ¨¡å‹åŸºæœ¬ä¿¡æ¯></p><blockquote><p>æˆ‘ä»¬å°†é‡‡ç”¨Qwen2-7Bæ¥è¿›è¡Œå¾®è°ƒ</p></blockquote><h2 id=1é…ç½®ç¯å¢ƒ>1.é…ç½®ç¯å¢ƒ</h2><h3 id=1autodlç®—åŠ›äº‘>(1)AutoDLç®—åŠ›äº‘</h3><p>æˆ‘ä»¬é€‰æ‹©AutoDLæœåŠ¡å™¨æ¥è®­ç»ƒ</p><p>ç§Ÿç”¨ä¸€ä¸ª3090å°±å¯ä»¥è®­ç»ƒQwen2-7Bäº†</p><p>åŸºç¡€é•œåƒé€‰æ‹©æœ€æ–°çš„å°±OK.</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e5%9f%ba%e7%a1%80%e9%95%9c%e5%83%8f.png alt=åŸºç¡€é•œåƒ></p><h3 id=2ä¸‹è½½qwen2çš„repo>(2)ä¸‹è½½Qwen2çš„repo</h3><p>é¦–å…ˆæˆ‘ä»¬æ‰¾åˆ°Qwen2çš„githubä»“åº“ï¼šhttps://github.com/QwenLM/Qwen2</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/QwenLM/Qwen2.git
</span></span></code></pre></div><p>ä½†æ˜¯æˆ‘ä»¬å¥½åƒå¹¶æ²¡æœ‰æ‰¾åˆ°<code>requirements.txt</code>æ–‡ä»¶ï¼Œåªåœ¨å…¶ä¸­æ‰¾åˆ°äº†ä¸€ä¸ªtransformersçš„ç‰ˆæœ¬è¦æ±‚ã€‚</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e9%85%8d%e7%bd%ae%e7%8e%af%e5%a2%83.png alt=æ¨¡å‹åŸºæœ¬ä¿¡æ¯></p><p><strong>æˆ‘ä»¬å¯ä»¥å‚è€ƒGLM4çš„ç¯å¢ƒæ¥é…ç½®ï¼Œå®æµ‹æ˜¯å¯ä»¥åŒ¹é…çš„ã€‚</strong></p><pre tabindex=0><code># use vllm
# vllm&gt;=0.5.0

# torch&gt;=2.3.0
# torchvision&gt;=0.18.0
transformers==4.40.0
huggingface-hub&gt;=0.23.1
sentencepiece&gt;=0.2.0
pydantic&gt;=2.7.1
timm&gt;=0.9.16
tiktoken&gt;=0.7.0
accelerate&gt;=0.30.1
sentence_transformers&gt;=2.7.0

# web demo
gradio&gt;=4.33.0

# openai demo
openai&gt;=1.34.0
einops&gt;=0.7.0
sse-starlette&gt;=2.1.0

# INT4
bitsandbytes&gt;=0.43.1

# PEFT model, not need if you don&#39;t use PEFT finetune model.
# peft&gt;=0.11.0
</code></pre><p><strong>æ³¨æ„å…¶ä¸­çš„torchè¦æ³¨é‡Šæ‰ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»é…ç½®äº†torchçš„ç‰ˆæœ¬ã€‚</strong></p><p>è¿™æ ·æˆ‘ä»¬çš„ç¯å¢ƒå°±é…ç½®å¥½äº†ã€‚</p><h2 id=2ä¸‹è½½æ¨¡å‹æ–‡ä»¶>2.ä¸‹è½½æ¨¡å‹æ–‡ä»¶</h2><p>æˆ‘ä»¬åœ¨é­”å¡”ç¤¾åŒºä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œé€‰æ‹©Qwen2-7B-Instructè¿›è¡Œæ¨¡å‹ä¸‹è½½</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e6%a8%a1%e5%9e%8b%e6%96%87%e4%bb%b6.png alt=æ¨¡å‹æ–‡ä»¶></p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e6%a8%a1%e5%9e%8b%e6%96%87%e4%bb%b62.png alt=æ¨¡å‹æ–‡ä»¶></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git lfs install
</span></span><span style=display:flex><span>git clone https://www.modelscope.cn/qwen/Qwen2-7B-Instruct.git
</span></span></code></pre></div><p>ä¹‹åæˆ‘ä»¬çš„æ¨¡å‹æ–‡ä»¶å°±ä¸‹è½½åˆ°æœåŠ¡å™¨äº†ã€‚</p><h2 id=3ä½“éªŒdemo>3.ä½“éªŒdemo</h2><p><strong>Qwen2æé«˜äº†ç»ˆç«¯demoå’Œwebdemoå¯ä»¥ä½“éªŒã€‚</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>cd</span> /Qwen2/examples/demo
</span></span></code></pre></div><ul><li>ç»ˆç«¯demo</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>python cli_demo.py
</span></span></code></pre></div><ul><li>webdemo</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>python web_demo.py
</span></span></code></pre></div><h2 id=4ä¸‹è½½llama-factory>4.ä¸‹è½½LLaMA-Factory</h2><p>æˆ‘ä»¬æ‰¾åˆ°LLaMA-Factoryçš„githubä»“åº“https://github.com/hiyouga/LLaMA-Factory/</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/hiyouga/LLaMA-Factory.git
</span></span></code></pre></div><p>ä¹‹åæˆ‘ä»¬å®‰è£…ç¯å¢ƒé…ç½®</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>pip install -e <span style=color:#f1fa8c>&#34;.[torch,metrics]&#34;</span>
</span></span></code></pre></div><h2 id=5æ„å»ºæ•°æ®é›†>5.æ„å»ºæ•°æ®é›†</h2><p><strong>æ ‡å‡†æ ¼å¼</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>[  
</span></span><span style=display:flex><span>  {  
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;instruction&#34;</span>: <span style=color:#f1fa8c>&#34;ç”¨æˆ·æŒ‡ä»¤ï¼ˆå¿…å¡«ï¼‰&#34;</span>,  
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;input&#34;</span>: <span style=color:#f1fa8c>&#34;ç”¨æˆ·è¾“å…¥ï¼ˆé€‰å¡«ï¼‰&#34;</span>,  
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;output&#34;</span>: <span style=color:#f1fa8c>&#34;æ¨¡å‹å›ç­”ï¼ˆå¿…å¡«ï¼‰&#34;</span>,  
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;system&#34;</span>: <span style=color:#f1fa8c>&#34;ç³»ç»Ÿæç¤ºè¯ï¼ˆé€‰å¡«ï¼‰&#34;</span>,  
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;history&#34;</span>: [  
</span></span><span style=display:flex><span>      [<span style=color:#f1fa8c>&#34;ç¬¬ä¸€è½®æŒ‡ä»¤ï¼ˆé€‰å¡«ï¼‰&#34;</span>, <span style=color:#f1fa8c>&#34;ç¬¬ä¸€è½®å›ç­”ï¼ˆé€‰å¡«ï¼‰&#34;</span>],  
</span></span><span style=display:flex><span>      [<span style=color:#f1fa8c>&#34;ç¬¬äºŒè½®æŒ‡ä»¤ï¼ˆé€‰å¡«ï¼‰&#34;</span>, <span style=color:#f1fa8c>&#34;ç¬¬äºŒè½®å›ç­”ï¼ˆé€‰å¡«ï¼‰&#34;</span>]  
</span></span><span style=display:flex><span>    ]  
</span></span><span style=display:flex><span>  }  
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>æˆ‘ä»¬è¿™é‡Œä¸¾ä¸€ä¸ªå°ä¾‹å­ï¼š</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>[
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;instruction&#34;</span>: <span style=color:#f1fa8c>&#34;æ ¹æ®ä¸‹åˆ—å¤§ç™½è¯å†™æˆæ­£å¼çš„ä¹¦é¢è®²è¯ç¨¿&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;input&#34;</span>: <span style=color:#f1fa8c>&#34;ä½ ä»¬ä»Šå¤©è·Ÿæˆ‘æŠ¥ä¸€ä¸ªï¼Œæ˜å¤©å†æŠ¥ä¸€ä¸ªï¼Œåå¤©å†æŠ¥ä¸€ä¸ªï¼Œæ¯æ¬¡æŠ¥å¾—éƒ½ä¸ä¸€æ ·&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;output&#34;</span>: <span style=color:#f1fa8c>&#34;è¦åšæŒå®äº‹æ±‚æ˜¯ï¼Œä¸åšå¼„è™šä½³ä½œçš„â€œèµ°ä¿®å‹â€å¹²éƒ¨ã€‚&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>æˆ‘ä»¬é€šè¿‡è¿™ç§æ ¼å¼æ„å»ºå®Œæ•°æ®é›†åï¼Œ<strong>æŠŠjsonæ–‡ä»¶æ”¾åˆ°dataæ–‡ä»¶å¤¹</strong></p><p>ä¹‹åæˆ‘ä»¬éœ€è¦åœ¨data_jsonæ–‡ä»¶å¤¹ä¸­åŠ å…¥è¿™ä¸ªæ•°æ®é›†</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#f1fa8c>&#34;Your dataset name&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;file_name&#34;</span>: <span style=color:#f1fa8c>&#34;Your dataset name.json&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>&#34;columns&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:#ff79c6>&#34;prompt&#34;</span>: <span style=color:#f1fa8c>&#34;instruction&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#ff79c6>&#34;query&#34;</span>: <span style=color:#f1fa8c>&#34;input&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#ff79c6>&#34;response&#34;</span>: <span style=color:#f1fa8c>&#34;output&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  },
</span></span></code></pre></div><p>è‡³æ­¤ï¼Œæ•°æ®é›†çš„æ„å»ºå°±å®Œæˆäº†ã€‚</p><h2 id=6å¼€å§‹è®­ç»ƒ>6.å¼€å§‹è®­ç»ƒï¼</h2><h3 id=å¯è§†åŒ–ç•Œé¢>å¯è§†åŒ–ç•Œé¢</h3><p>æˆ‘ä»¬è¾“å…¥å‘½ä»¤è¿›å»å¯è§†åŒ–ç•Œé¢</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>llamafactory-cli webui
</span></span></code></pre></div><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/LLAMA.png alt="LLAMA Board"></p><h3 id=è®­ç»ƒå…³é”®å‚æ•°>è®­ç»ƒå…³é”®å‚æ•°</h3><ul><li><p>æ¨¡å‹åç§°ï¼šé€‰æ‹©Qwen2-7B-Chat</p></li><li><p>æ¨¡å‹è·¯å¾„ï¼šé€‰æ‹©ä½ çš„æ¨¡å‹è·¯å¾„ï¼ˆæˆ‘è¿™é‡Œæ˜¯/root/autodl-tmp/Qwen2/Qwen2-7B-Instructï¼‰</p></li><li><p>å¾®è°ƒæ–¹æ³•ï¼šLora</p></li><li><p>æ•°æ®é›†ï¼šé€‰æ‹©è‡ªå·±æ„å»ºçš„æ•°æ®é›†ï¼ˆæˆ‘è¿™é‡Œæ˜¯NL2Speechï¼‰</p></li></ul><p>å¯ä»¥ç‚¹å‡»é¢„è§ˆçœ‹åˆ°æ•°æ®é›†</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e9%a2%84%e8%a7%88%e6%95%b0%e6%8d%ae%e9%9b%86.png alt=é¢„è§ˆæ•°æ®é›†></p><ul><li>è®­ç»ƒè½®æ•°ï¼š30.0</li><li>æ‰¹å¤„ç†å¤§å°(batch_size)ï¼š2</li><li>éªŒè¯é›†æ¯”ä¾‹</li></ul><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/LLAMA2.png alt="LLAMA Board2"></p><p>ä¹‹åæˆ‘ä»¬ç‚¹å‡»<strong>é¢„è§ˆå‘½ä»¤</strong>å°±å¯ä»¥çœ‹åˆ°å…·ä½“çš„å‘½ä»¤ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>llamafactory-cli train <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --stage sft <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --do_train True <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --model_name_or_path /root/autodl-tmp/Qwen2/Qwen2-7B-Instruct <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --preprocessing_num_workers <span style=color:#bd93f9>16</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --finetuning_type lora <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --quantization_method bitsandbytes <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --template qwen <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --flash_attn auto <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --dataset_dir data <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --dataset NL2Speech <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --cutoff_len <span style=color:#bd93f9>1024</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --learning_rate 5e-05 <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --num_train_epochs 30.0 <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --max_samples <span style=color:#bd93f9>100000</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --per_device_train_batch_size <span style=color:#bd93f9>2</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --gradient_accumulation_steps <span style=color:#bd93f9>8</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --lr_scheduler_type cosine <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --max_grad_norm 1.0 <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --logging_steps <span style=color:#bd93f9>5</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --save_steps <span style=color:#bd93f9>100</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --warmup_steps <span style=color:#bd93f9>0</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --optim adamw_torch <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --packing False <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --report_to none <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --output_dir saves/Qwen2-7B-Chat/lora/train_2024-07-25-20-43-13 <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --bf16 True <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --plot_loss True <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --ddp_timeout <span style=color:#bd93f9>180000000</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --include_num_input_tokens_seen True <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --lora_rank <span style=color:#bd93f9>8</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --lora_alpha <span style=color:#bd93f9>16</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --lora_dropout <span style=color:#bd93f9>0</span> <span style=color:#f1fa8c>\
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c></span>    --lora_target all
</span></span></code></pre></div><p>ä¹‹åç‚¹å‡»<strong>ä¿å­˜è®­ç»ƒå‚æ•°</strong>å’Œ<strong>è½½å…¥è®­ç»ƒå‚æ•°</strong></p><h3 id=è®­ç»ƒ>è®­ç»ƒ</h3><p>ç‚¹å‡»<strong>å¼€å§‹</strong>å°±è®­ç»ƒäº†ï¼</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e8%ae%ad%e7%bb%83.png alt=è®­ç»ƒ></p><p>æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹è®­ç»ƒæ‰€å ç”¨çš„æ˜¾å­˜ï¼Œå¤§æ¦‚å ç”¨16ä¸ªGå·¦å³ã€‚</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/CUDA.png alt=æ˜¾å­˜></p><p>ä¹‹åç­‰åˆ°è®­ç»ƒç»“æŸã€‚</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e8%ae%ad%e7%bb%83%e7%bb%93%e6%9d%9f.png alt=è®­ç»ƒç»“æŸ></p><h3 id=æ£€æµ‹è®­ç»ƒæˆæœ>æ£€æµ‹è®­ç»ƒæˆæœ</h3><p>æˆ‘ä»¬åŠ å…¥<strong>æ£€æŸ¥ç‚¹è·¯å¾„</strong>å’Œç‚¹å‡»<strong>Chat</strong>ï¼Œä¹‹å<strong>åŠ è½½æ¨¡å‹</strong>ï¼Œå°±å¯ä»¥è¿›è¡Œå¯¹è¯æ¥æ£€æµ‹è®­ç»ƒæˆæœäº†ã€‚</p><p>![Chat](/img/2024-07-25-LLM-å¿«é€Ÿå…¥é—¨/Chat demo.png)</p><h2 id=7å¯¼å‡º>7.å¯¼å‡º</h2><p>ç‚¹å‡»<strong>Export</strong>ï¼Œé€‰æ‹©è‡ªå·±çš„<strong>å¯¼å‡ºç›®å½•</strong>ï¼Œä¹‹å<strong>å¼€å§‹å¯¼å‡º</strong>ã€‚</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/%e5%af%bc%e5%87%ba.png alt=å¯¼å‡º></p><p>ç­‰å¾…å¯¼å‡ºå®Œæˆåå°±ä¼šå‡ºç°åœ¨å¯¼å‡ºç›®å½•ä¸­äº†ã€‚</p><h2 id=8ä½“éªŒdemo>8.ä½“éªŒDemo</h2><p>æˆ‘ä»¬è¿”å›åˆ°Qwen2çš„demoæ–‡ä»¶é‡Œã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>cd</span> /Qwen2/examples/demo
</span></span></code></pre></div><p>æˆ‘ä»¬ä¿®æ”¹<strong>web_demo.py</strong>æ–‡ä»¶ï¼Œå°†<code>DEFAULT_CKPT_PATH</code>è®¾ç½®ä¸ºè‡ªå·±çš„è·¯å¾„ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>DEFAULT_CKPT_PATH <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#39;/root/autodl-tmp/Qwen2/outputs/SleepingFace Test&#39;</span>
</span></span></code></pre></div><p>ä¹‹åæ‰§è¡Œ<strong>web_demo.py</strong>æ–‡ä»¶ï¼Œå°±å¯ä»¥ä½“éªŒè‡ªå·±å¾®è°ƒå¥½çš„æ¨¡å‹äº†ã€‚</p><pre tabindex=0><code class=language-she data-lang=she>python web_demo.py
</code></pre><p>è¿™é‡Œç»™å‡ºä¸€ä¸ªå¯ä»¥streamlitæ„å»ºçš„demoæ–‡ä»¶ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> json
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> streamlit <span style=color:#ff79c6>as</span> st
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> AutoModelForCausalLM, AutoTokenizer
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers.generation.utils <span style=color:#ff79c6>import</span> GenerationConfig
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>st<span style=color:#ff79c6>.</span>set_page_config(page_title<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;SleepingFace-ChatğŸ˜´&#34;</span>)
</span></span><span style=display:flex><span>st<span style=color:#ff79c6>.</span>title(<span style=color:#f1fa8c>&#34;SleepingFace-ChatğŸ˜´&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>@st.cache_resource
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>init_model</span>():
</span></span><span style=display:flex><span>    model <span style=color:#ff79c6>=</span> AutoModelForCausalLM<span style=color:#ff79c6>.</span>from_pretrained(
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;/root/autodl-tmp/Qwen2/outputs/SleepingFace v2&#34;</span>,
</span></span><span style=display:flex><span>        torch_dtype<span style=color:#ff79c6>=</span>torch<span style=color:#ff79c6>.</span>float16,
</span></span><span style=display:flex><span>        device_map<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;auto&#34;</span>,
</span></span><span style=display:flex><span>        trust_remote_code<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>.</span>generation_config <span style=color:#ff79c6>=</span> GenerationConfig<span style=color:#ff79c6>.</span>from_pretrained(
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;/root/autodl-tmp/Qwen2/outputs/SleepingFace v2&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    tokenizer <span style=color:#ff79c6>=</span> AutoTokenizer<span style=color:#ff79c6>.</span>from_pretrained(
</span></span><span style=display:flex><span>        <span style=color:#f1fa8c>&#34;/root/autodl-tmp/Qwen2/outputs/SleepingFace v2&#34;</span>,
</span></span><span style=display:flex><span>        use_fast<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>,
</span></span><span style=display:flex><span>        trust_remote_code<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> model, tokenizer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>clear_chat_history</span>():
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>del</span> st<span style=color:#ff79c6>.</span>session_state<span style=color:#ff79c6>.</span>messages
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>init_chat_history</span>():
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>with</span> st<span style=color:#ff79c6>.</span>chat_message(<span style=color:#f1fa8c>&#34;assistant&#34;</span>, avatar<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;ğŸ¤–&#39;</span>):
</span></span><span style=display:flex><span>        st<span style=color:#ff79c6>.</span>markdown(<span style=color:#f1fa8c>&#34;æ‚¨å¥½ï¼Œæˆ‘æ˜¯SleepingFaceå°åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ğŸ˜´&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> <span style=color:#f1fa8c>&#34;messages&#34;</span> <span style=color:#ff79c6>in</span> st<span style=color:#ff79c6>.</span>session_state:
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>for</span> message <span style=color:#ff79c6>in</span> st<span style=color:#ff79c6>.</span>session_state<span style=color:#ff79c6>.</span>messages:
</span></span><span style=display:flex><span>            avatar <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#39;ğŸ˜´&#39;</span> <span style=color:#ff79c6>if</span> message[<span style=color:#f1fa8c>&#34;role&#34;</span>] <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;user&#34;</span> <span style=color:#ff79c6>else</span> <span style=color:#f1fa8c>&#39;ğŸ¤–&#39;</span>
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>with</span> st<span style=color:#ff79c6>.</span>chat_message(message[<span style=color:#f1fa8c>&#34;role&#34;</span>], avatar<span style=color:#ff79c6>=</span>avatar):
</span></span><span style=display:flex><span>                st<span style=color:#ff79c6>.</span>markdown(message[<span style=color:#f1fa8c>&#34;content&#34;</span>])
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>        st<span style=color:#ff79c6>.</span>session_state<span style=color:#ff79c6>.</span>messages <span style=color:#ff79c6>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> st<span style=color:#ff79c6>.</span>session_state<span style=color:#ff79c6>.</span>messages
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>generate_response</span>(model, tokenizer, messages):
</span></span><span style=display:flex><span>    <span style=color:#6272a4># Prepare the input text by concatenating all messages</span>
</span></span><span style=display:flex><span>    input_text <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> message <span style=color:#ff79c6>in</span> messages:
</span></span><span style=display:flex><span>        role <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;User&#34;</span> <span style=color:#ff79c6>if</span> message[<span style=color:#f1fa8c>&#34;role&#34;</span>] <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;user&#34;</span> <span style=color:#ff79c6>else</span> <span style=color:#f1fa8c>&#34;Assistant&#34;</span>
</span></span><span style=display:flex><span>        input_text <span style=color:#ff79c6>+=</span> <span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;</span><span style=color:#f1fa8c>{</span>role<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>: </span><span style=color:#f1fa8c>{</span>message[<span style=color:#f1fa8c>&#39;content&#39;</span>]<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># Encode the input text</span>
</span></span><span style=display:flex><span>    inputs <span style=color:#ff79c6>=</span> tokenizer<span style=color:#ff79c6>.</span>encode(input_text, return_tensors<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;pt&#34;</span>)<span style=color:#ff79c6>.</span>to(model<span style=color:#ff79c6>.</span>device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># Generate a response</span>
</span></span><span style=display:flex><span>    outputs <span style=color:#ff79c6>=</span> model<span style=color:#ff79c6>.</span>generate(inputs, max_length<span style=color:#ff79c6>=</span><span style=color:#bd93f9>6000</span>, do_sample<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>    response <span style=color:#ff79c6>=</span> tokenizer<span style=color:#ff79c6>.</span>decode(outputs[<span style=color:#bd93f9>0</span>], skip_special_tokens<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># Extract the assistant&#39;s response part</span>
</span></span><span style=display:flex><span>    response <span style=color:#ff79c6>=</span> response<span style=color:#ff79c6>.</span>split(<span style=color:#f1fa8c>&#34;Assistant:&#34;</span>)[<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>]<span style=color:#ff79c6>.</span>strip()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> response
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>main</span>():
</span></span><span style=display:flex><span>    model, tokenizer <span style=color:#ff79c6>=</span> init_model()
</span></span><span style=display:flex><span>    messages <span style=color:#ff79c6>=</span> init_chat_history()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> prompt <span style=color:#ff79c6>:=</span> st<span style=color:#ff79c6>.</span>chat_input(<span style=color:#f1fa8c>&#34;Shift + Enter æ¢è¡Œ, Enter å‘é€&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>with</span> st<span style=color:#ff79c6>.</span>chat_message(<span style=color:#f1fa8c>&#34;user&#34;</span>, avatar<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;ğŸ˜´&#39;</span>):
</span></span><span style=display:flex><span>            st<span style=color:#ff79c6>.</span>markdown(prompt)
</span></span><span style=display:flex><span>        messages<span style=color:#ff79c6>.</span>append({<span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;user&#34;</span>, <span style=color:#f1fa8c>&#34;content&#34;</span>: prompt})
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;[user] </span><span style=color:#f1fa8c>{</span>prompt<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>&#34;</span>, flush<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>with</span> st<span style=color:#ff79c6>.</span>chat_message(<span style=color:#f1fa8c>&#34;assistant&#34;</span>, avatar<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;ğŸ¤–&#39;</span>):
</span></span><span style=display:flex><span>            placeholder <span style=color:#ff79c6>=</span> st<span style=color:#ff79c6>.</span>empty()
</span></span><span style=display:flex><span>            response <span style=color:#ff79c6>=</span> generate_response(model, tokenizer, messages)
</span></span><span style=display:flex><span>            placeholder<span style=color:#ff79c6>.</span>markdown(response)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        messages<span style=color:#ff79c6>.</span>append({<span style=color:#f1fa8c>&#34;role&#34;</span>: <span style=color:#f1fa8c>&#34;assistant&#34;</span>, <span style=color:#f1fa8c>&#34;content&#34;</span>: response})
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>print</span>(json<span style=color:#ff79c6>.</span>dumps(messages, ensure_ascii<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>), flush<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        st<span style=color:#ff79c6>.</span>button(<span style=color:#f1fa8c>&#34;æ¸…ç©ºå¯¹è¯&#34;</span>, on_click<span style=color:#ff79c6>=</span>clear_chat_history)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> __name__ <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    main()
</span></span></code></pre></div><p>ä¹‹åè¿˜åœ¨è¯¥ç›®å½•ä¸‹æ‰§è¡Œ</p><pre tabindex=0><code class=language-she data-lang=she>streamlit run web_demo_streamlit.py --server.port 6006
</code></pre><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/demo.png alt=demo></p><p>æˆ‘ä»¬å¯ä»¥å¼€å§‹å¯¹è¯æ£€æŸ¥åˆšåˆšè®­ç»ƒçš„æˆæœã€‚</p><p><img src=/img/2024-07-25-LLM-%e5%bf%ab%e9%80%9f%e5%85%a5%e9%97%a8/demo2.png alt=demo></p><p>è‡³æ­¤å°±å®Œæˆå¿«é€Ÿå…¥é—¨å•¦ï¼</p><p>å¦‚æœæ‚¨é‡åˆ°é—®é¢˜è¯·åœ¨è¯„è®ºåŒºè¯„è®ºï¼</p><div class="entry-shang text-center"><p>ã€Œç»™ä¸ªèµèµï¼Œæ”¯æŒä¸€ä¸‹ä½œè€…å§~ã€</p><button class="zs show-zs btn btn-bred">èµèµæ”¯æŒ</button></div><div class=zs-modal-bg></div><div class=zs-modal-box><div class=zs-modal-head><button type=button class=close>Ã—</button>
<span class=author><a href=https://wangzhendong20.github.io/><img src=/img/favicon.png>SleepingFace Blog</a></span><p class=tip><i></i><span>ç»™ä¸ªèµèµï¼Œæ”¯æŒä¸€ä¸‹ä½œè€…å§~</span></p></div><div class=zs-modal-body><div class=zs-modal-btns><button class="btn btn-blink" data-num=2>2å…ƒ</button>
<button class="btn btn-blink" data-num=5>5å…ƒ</button>
<button class="btn btn-blink" data-num=10>10å…ƒ</button>
<button class="btn btn-blink" data-num=50>50å…ƒ</button>
<button class="btn btn-blink" data-num=100>100å…ƒ</button>
<button class="btn btn-blink" data-num=1>ä»»æ„é‡‘é¢</button></div><div class=zs-modal-pay><button class="btn btn-bred" id=pay-text>2å…ƒ</button><p>ä½¿ç”¨<span id=pay-type>å¾®ä¿¡</span>æ‰«æäºŒç»´ç å®Œæˆæ”¯ä»˜</p><img src=/img/reward/wechat-2.png id=pay-image></div></div><div class=zs-modal-footer><label><input type=radio name=zs-type value=wechat class=zs-type checked><span><span class=zs-wechat><img src=/img/reward/wechat-btn.png></span></label>
<label><input type=radio name=zs-type value=alipay class=zs-type class=zs-alipay><img src=/img/reward/alipay-btn.png></span></label></div></div><script type=text/javascript src=/js/reward.js></script><hr><ul class=pager><li class=previous><a href=/2024/07/23/leetcode-note/ data-toggle=tooltip data-placement=top title=ä»£ç éšæƒ³å½•+leetcodeç¬”è®°>&larr;
Previous Post</a></li><li class=next><a href=/2024/07/29/2024-7-29-Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/ data-toggle=tooltip data-placement=top title=Gitå¸¸ç”¨å‘½ä»¤>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=wangzhendong20/wangzhendong20.github.io data-repo-id=***************************** data-category=**************************** data-category-id=************************** data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=en crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/java title=java>java
</a><a href=/tags/leetcode title=leetcode>leetcode
</a><a href=/tags/%E7%AE%97%E6%B3%95 title=ç®—æ³•>ç®—æ³•</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://tanxiangyuu.github.io>è°­æ€»çš„åšå®¢</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:wangzhendong20@163.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/wangzhendong20><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="SleepingFace Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">&copy; SleepingFace Blog 2024<br><a>æ¬¢è¿è¯„è®ºå“¦ï¼</a></p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><script>var _baId="8cc115b1ee28b68ce1138a4281875e00",_hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="//hm.baidu.com/hm.js?"+_baId,e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){t=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),n=$(this).text(),i=$('<a href="'+o+'" rel="nofollow">'+n+"</a>"),s=$('<li class="'+t+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>